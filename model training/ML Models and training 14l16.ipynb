{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "#загрузка массива данных для обучения моделей\n",
    "filename='data14'\n",
    "\n",
    "imall,yy = pickle.load(open(filename, 'rb'))\n",
    "# масштабирование величины яркости пикселей из формы 0-255 в форму 0 - 1\n",
    "imall=imall/255.0\n",
    "yy.shape\n",
    "weight=(len(yy)-yy.sum())/yy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#отрисовка элемената b и вывод значения сфера или нет\n",
    "b=4121\n",
    "plt.imshow(np.reshape(imall[b,:],(32,32)))\n",
    "yy[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбивка массива анных на тестовую 5% и обучающую выборки 95%\n",
    "from sklearn.model_selection import  train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(imall,yy,random_state=0,test_size=0.05)\n",
    "\n",
    "\n",
    "#преобразование формы массива для ее соответствия функции fit керас\n",
    "Xtrain=np.reshape(Xtrain,(len(Xtrain),32,32,1)).astype('float32')\n",
    "ytrain=np.reshape(ytrain,(len(ytrain),1)).astype('float32')\n",
    "Xtest=np.reshape(Xtest,(len(Xtest),32,32,1)).astype('float32')\n",
    "ytest=np.reshape(ytest,(len(ytest),1)).astype('float32')\n",
    "\n",
    "ytr1=np.zeros((len(ytrain),1))\n",
    "ytr2=np.zeros((len(ytrain),1))\n",
    "ytr1[ytrain==0]=1\n",
    "ytr1[ytrain==1]=1\n",
    "ytr=np.hstack((ytr1,ytr2))\n",
    "\n",
    "yte1=np.zeros((len(ytest),1))\n",
    "yte2=np.zeros((len(ytest),1))\n",
    "yte1[ytest==0]=1\n",
    "yte1[ytest==1]=1\n",
    "yte=np.hstack((yte1,yte2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузка керас и тензорфлоу\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "#keras import and windows InteractiveSession bug fix\n",
    "from tensorflow.keras.optimizers import SGD,schedules\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import metrics as ms\n",
    "from tensorflow.keras import  Model\n",
    "from tensorflow.keras.layers import Input,Conv2D, Concatenate, MaxPooling2D,Activation,concatenate,AveragePooling2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Dropout, BatchNormalization,Flatten,Dense,Reshape\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Concatenate, MaxPooling2D,Conv2DTranspose,Input\n",
    "from tensorflow.keras.layers import UpSampling2D, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                32800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,577\n",
      "Trainable params: 56,353\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "734/734 [==============================] - 35s 27ms/step - loss: 0.1472 - accuracy: 0.9770 - val_loss: 0.0487 - val_accuracy: 0.9813\n",
      "Epoch 2/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.1064 - accuracy: 0.9799 - val_loss: 0.0407 - val_accuracy: 0.9848\n",
      "Epoch 3/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.1024 - accuracy: 0.9806 - val_loss: 0.0582 - val_accuracy: 0.9781\n",
      "Epoch 4/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0971 - accuracy: 0.9815 - val_loss: 0.0358 - val_accuracy: 0.9866\n",
      "Epoch 5/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0938 - accuracy: 0.9822 - val_loss: 0.0314 - val_accuracy: 0.9888\n",
      "Epoch 6/200\n",
      "734/734 [==============================] - 19s 26ms/step - loss: 0.0925 - accuracy: 0.9822 - val_loss: 0.0470 - val_accuracy: 0.9826\n",
      "Epoch 7/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0902 - accuracy: 0.9829 - val_loss: 0.0264 - val_accuracy: 0.9905\n",
      "Epoch 8/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0872 - accuracy: 0.9831 - val_loss: 0.0422 - val_accuracy: 0.9846\n",
      "Epoch 9/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0875 - accuracy: 0.9833 - val_loss: 0.0388 - val_accuracy: 0.9856\n",
      "Epoch 10/200\n",
      "734/734 [==============================] - 19s 26ms/step - loss: 0.0853 - accuracy: 0.9835 - val_loss: 0.0588 - val_accuracy: 0.9790\n",
      "Epoch 11/200\n",
      "734/734 [==============================] - 19s 26ms/step - loss: 0.0850 - accuracy: 0.9839 - val_loss: 0.0343 - val_accuracy: 0.9876\n",
      "Epoch 12/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0850 - accuracy: 0.9837 - val_loss: 0.0445 - val_accuracy: 0.9837\n",
      "Epoch 13/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0830 - accuracy: 0.9839 - val_loss: 0.0388 - val_accuracy: 0.9858\n",
      "Epoch 14/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0811 - accuracy: 0.9844 - val_loss: 0.0326 - val_accuracy: 0.9880\n",
      "Epoch 15/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0805 - accuracy: 0.9844 - val_loss: 0.0278 - val_accuracy: 0.9896\n",
      "Epoch 16/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0801 - accuracy: 0.9846 - val_loss: 0.0284 - val_accuracy: 0.9901\n",
      "Epoch 17/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0799 - accuracy: 0.9845 - val_loss: 0.0457 - val_accuracy: 0.9837\n",
      "Epoch 18/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0774 - accuracy: 0.9847 - val_loss: 0.0478 - val_accuracy: 0.9827\n",
      "Epoch 19/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0770 - accuracy: 0.9847 - val_loss: 0.0288 - val_accuracy: 0.9899\n",
      "Epoch 20/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0771 - accuracy: 0.9848 - val_loss: 0.0402 - val_accuracy: 0.9853\n",
      "Epoch 21/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0755 - accuracy: 0.9853 - val_loss: 0.0311 - val_accuracy: 0.9891\n",
      "Epoch 22/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0752 - accuracy: 0.9852 - val_loss: 0.0303 - val_accuracy: 0.9891\n",
      "Epoch 23/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0754 - accuracy: 0.9852 - val_loss: 0.0475 - val_accuracy: 0.9831\n",
      "Epoch 24/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0746 - accuracy: 0.9854 - val_loss: 0.0362 - val_accuracy: 0.9870\n",
      "Epoch 25/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0735 - accuracy: 0.9854 - val_loss: 0.0262 - val_accuracy: 0.9908\n",
      "Epoch 26/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0742 - accuracy: 0.9854 - val_loss: 0.0285 - val_accuracy: 0.9896\n",
      "Epoch 27/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0740 - accuracy: 0.9854 - val_loss: 0.0295 - val_accuracy: 0.9893\n",
      "Epoch 28/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0733 - accuracy: 0.9855 - val_loss: 0.0294 - val_accuracy: 0.9894\n",
      "Epoch 29/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0730 - accuracy: 0.9855 - val_loss: 0.0307 - val_accuracy: 0.9889\n",
      "Epoch 30/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0710 - accuracy: 0.9859 - val_loss: 0.0545 - val_accuracy: 0.9808\n",
      "Epoch 31/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0727 - accuracy: 0.9857 - val_loss: 0.0298 - val_accuracy: 0.9894\n",
      "Epoch 32/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0714 - accuracy: 0.9857 - val_loss: 0.0432 - val_accuracy: 0.9851\n",
      "Epoch 33/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0711 - accuracy: 0.9861 - val_loss: 0.0385 - val_accuracy: 0.9862\n",
      "Epoch 34/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0705 - accuracy: 0.9861 - val_loss: 0.0321 - val_accuracy: 0.9890\n",
      "Epoch 35/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0699 - accuracy: 0.9861 - val_loss: 0.0291 - val_accuracy: 0.9897\n",
      "Epoch 36/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0705 - accuracy: 0.9859 - val_loss: 0.0263 - val_accuracy: 0.9906\n",
      "Epoch 37/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0698 - accuracy: 0.9862 - val_loss: 0.0367 - val_accuracy: 0.9870\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0678 - accuracy: 0.9863 - val_loss: 0.0261 - val_accuracy: 0.9907\n",
      "Epoch 39/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0682 - accuracy: 0.9863 - val_loss: 0.0509 - val_accuracy: 0.9825\n",
      "Epoch 40/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0687 - accuracy: 0.9864 - val_loss: 0.0487 - val_accuracy: 0.9833\n",
      "Epoch 41/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0685 - accuracy: 0.9864 - val_loss: 0.0313 - val_accuracy: 0.9891\n",
      "Epoch 42/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0678 - accuracy: 0.9865 - val_loss: 0.0418 - val_accuracy: 0.9855\n",
      "Epoch 43/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0682 - accuracy: 0.9865 - val_loss: 0.0322 - val_accuracy: 0.9886\n",
      "Epoch 44/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0649 - accuracy: 0.9868 - val_loss: 0.0317 - val_accuracy: 0.9886\n",
      "Epoch 45/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0666 - accuracy: 0.9868 - val_loss: 0.0549 - val_accuracy: 0.9817\n",
      "Epoch 46/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0657 - accuracy: 0.9868 - val_loss: 0.0292 - val_accuracy: 0.9898\n",
      "Epoch 47/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0662 - accuracy: 0.9868 - val_loss: 0.0273 - val_accuracy: 0.9903\n",
      "Epoch 48/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0662 - accuracy: 0.9867 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 49/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 0.0344 - val_accuracy: 0.9880\n",
      "Epoch 50/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0651 - accuracy: 0.9865 - val_loss: 0.0459 - val_accuracy: 0.9844\n",
      "Epoch 51/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0524 - val_accuracy: 0.9823\n",
      "Epoch 52/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0659 - accuracy: 0.9868 - val_loss: 0.0302 - val_accuracy: 0.9894\n",
      "Epoch 53/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0644 - accuracy: 0.9867 - val_loss: 0.0423 - val_accuracy: 0.9859\n",
      "Epoch 54/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0644 - accuracy: 0.9870 - val_loss: 0.0314 - val_accuracy: 0.9889\n",
      "Epoch 55/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0652 - accuracy: 0.9868 - val_loss: 0.0383 - val_accuracy: 0.9872\n",
      "Epoch 56/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0657 - accuracy: 0.9869 - val_loss: 0.0261 - val_accuracy: 0.9906\n",
      "Epoch 57/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0627 - accuracy: 0.9872 - val_loss: 0.0273 - val_accuracy: 0.9903\n",
      "Epoch 58/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0633 - accuracy: 0.9873 - val_loss: 0.0245 - val_accuracy: 0.9914\n",
      "Epoch 59/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0620 - accuracy: 0.9871 - val_loss: 0.0261 - val_accuracy: 0.9908\n",
      "Epoch 60/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0633 - accuracy: 0.9872 - val_loss: 0.0282 - val_accuracy: 0.9900\n",
      "Epoch 61/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0621 - accuracy: 0.9874 - val_loss: 0.0260 - val_accuracy: 0.9907\n",
      "Epoch 62/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0630 - accuracy: 0.9873 - val_loss: 0.0236 - val_accuracy: 0.9919\n",
      "Epoch 63/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0622 - accuracy: 0.9872 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
      "Epoch 64/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0612 - accuracy: 0.9873 - val_loss: 0.0340 - val_accuracy: 0.9884\n",
      "Epoch 65/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0607 - accuracy: 0.9876 - val_loss: 0.0252 - val_accuracy: 0.9915\n",
      "Epoch 66/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0617 - accuracy: 0.9873 - val_loss: 0.0246 - val_accuracy: 0.9917\n",
      "Epoch 67/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0599 - accuracy: 0.9876 - val_loss: 0.0290 - val_accuracy: 0.9899\n",
      "Epoch 68/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0619 - accuracy: 0.9875 - val_loss: 0.0470 - val_accuracy: 0.9838\n",
      "Epoch 69/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0609 - accuracy: 0.9874 - val_loss: 0.0465 - val_accuracy: 0.9843\n",
      "Epoch 70/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0607 - accuracy: 0.9875 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 71/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0613 - accuracy: 0.9875 - val_loss: 0.0356 - val_accuracy: 0.9880\n",
      "Epoch 72/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0609 - accuracy: 0.9875 - val_loss: 0.0297 - val_accuracy: 0.9895\n",
      "Epoch 73/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0609 - accuracy: 0.9875 - val_loss: 0.0471 - val_accuracy: 0.9844\n",
      "Epoch 74/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0602 - accuracy: 0.9876 - val_loss: 0.0297 - val_accuracy: 0.9898\n",
      "Epoch 75/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0604 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9864\n",
      "Epoch 76/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0586 - accuracy: 0.9877 - val_loss: 0.0461 - val_accuracy: 0.9845\n",
      "Epoch 77/200\n",
      "734/734 [==============================] - 19s 26ms/step - loss: 0.0579 - accuracy: 0.9880 - val_loss: 0.0256 - val_accuracy: 0.9910\n",
      "Epoch 78/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0597 - accuracy: 0.9878 - val_loss: 0.0235 - val_accuracy: 0.9920\n",
      "Epoch 79/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0588 - accuracy: 0.9878 - val_loss: 0.0420 - val_accuracy: 0.9854\n",
      "Epoch 80/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0586 - accuracy: 0.9879 - val_loss: 0.0289 - val_accuracy: 0.9897\n",
      "Epoch 81/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0585 - accuracy: 0.9880 - val_loss: 0.0242 - val_accuracy: 0.9915\n",
      "Epoch 82/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0584 - accuracy: 0.9880 - val_loss: 0.0240 - val_accuracy: 0.9917\n",
      "Epoch 83/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0581 - accuracy: 0.9879 - val_loss: 0.0269 - val_accuracy: 0.9904\n",
      "Epoch 84/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0578 - accuracy: 0.9879 - val_loss: 0.0446 - val_accuracy: 0.9847\n",
      "Epoch 85/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0582 - accuracy: 0.9877 - val_loss: 0.0244 - val_accuracy: 0.9913\n",
      "Epoch 86/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0575 - accuracy: 0.9880 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 87/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0568 - accuracy: 0.9881 - val_loss: 0.0297 - val_accuracy: 0.9895\n",
      "Epoch 88/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0577 - accuracy: 0.9880 - val_loss: 0.0241 - val_accuracy: 0.9915\n",
      "Epoch 89/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0581 - accuracy: 0.9878 - val_loss: 0.0282 - val_accuracy: 0.9903\n",
      "Epoch 90/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0582 - accuracy: 0.9880 - val_loss: 0.0235 - val_accuracy: 0.9918\n",
      "Epoch 91/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0565 - accuracy: 0.9882 - val_loss: 0.0241 - val_accuracy: 0.9918\n",
      "Epoch 92/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0564 - accuracy: 0.9883 - val_loss: 0.0348 - val_accuracy: 0.9883\n",
      "Epoch 93/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0567 - accuracy: 0.9883 - val_loss: 0.0411 - val_accuracy: 0.9867\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0564 - accuracy: 0.9883 - val_loss: 0.0291 - val_accuracy: 0.9896\n",
      "Epoch 95/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0561 - accuracy: 0.9883 - val_loss: 0.0261 - val_accuracy: 0.9911\n",
      "Epoch 96/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0572 - accuracy: 0.9881 - val_loss: 0.0329 - val_accuracy: 0.9886\n",
      "Epoch 97/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0558 - accuracy: 0.9884 - val_loss: 0.0233 - val_accuracy: 0.9919\n",
      "Epoch 98/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0565 - accuracy: 0.9882 - val_loss: 0.0264 - val_accuracy: 0.9909\n",
      "Epoch 99/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0560 - accuracy: 0.9881 - val_loss: 0.0270 - val_accuracy: 0.9905\n",
      "Epoch 100/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0564 - accuracy: 0.9882 - val_loss: 0.0265 - val_accuracy: 0.9909\n",
      "Epoch 101/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0553 - accuracy: 0.9884 - val_loss: 0.0262 - val_accuracy: 0.9907\n",
      "Epoch 102/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0562 - accuracy: 0.9883 - val_loss: 0.0250 - val_accuracy: 0.9912\n",
      "Epoch 103/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0552 - accuracy: 0.9883 - val_loss: 0.0352 - val_accuracy: 0.9878\n",
      "Epoch 104/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0550 - accuracy: 0.9884 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 105/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0553 - accuracy: 0.9884 - val_loss: 0.0295 - val_accuracy: 0.9897\n",
      "Epoch 106/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0555 - accuracy: 0.9884 - val_loss: 0.0533 - val_accuracy: 0.9824\n",
      "Epoch 107/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0545 - accuracy: 0.9885 - val_loss: 0.0350 - val_accuracy: 0.9878\n",
      "Epoch 108/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0561 - accuracy: 0.9881 - val_loss: 0.0249 - val_accuracy: 0.9913\n",
      "Epoch 109/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0554 - accuracy: 0.9884 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 110/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0538 - accuracy: 0.9888 - val_loss: 0.0264 - val_accuracy: 0.9906\n",
      "Epoch 111/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0554 - accuracy: 0.9884 - val_loss: 0.0406 - val_accuracy: 0.9864\n",
      "Epoch 112/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0545 - accuracy: 0.9885 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 113/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0553 - accuracy: 0.9884 - val_loss: 0.0288 - val_accuracy: 0.9900\n",
      "Epoch 114/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0543 - accuracy: 0.9886 - val_loss: 0.0256 - val_accuracy: 0.9911\n",
      "Epoch 115/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0536 - accuracy: 0.9887 - val_loss: 0.0244 - val_accuracy: 0.9911\n",
      "Epoch 116/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0543 - accuracy: 0.9886 - val_loss: 0.0246 - val_accuracy: 0.9914\n",
      "Epoch 117/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0541 - accuracy: 0.9888 - val_loss: 0.0239 - val_accuracy: 0.9916\n",
      "Epoch 118/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0541 - accuracy: 0.9886 - val_loss: 0.0231 - val_accuracy: 0.9921\n",
      "Epoch 119/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0531 - accuracy: 0.9889 - val_loss: 0.0311 - val_accuracy: 0.9893\n",
      "Epoch 120/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0539 - accuracy: 0.9886 - val_loss: 0.0262 - val_accuracy: 0.9913\n",
      "Epoch 121/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0527 - accuracy: 0.9887 - val_loss: 0.0342 - val_accuracy: 0.9883\n",
      "Epoch 122/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0537 - accuracy: 0.9887 - val_loss: 0.0250 - val_accuracy: 0.9917\n",
      "Epoch 123/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0530 - accuracy: 0.9887 - val_loss: 0.0286 - val_accuracy: 0.9902\n",
      "Epoch 124/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0526 - accuracy: 0.9889 - val_loss: 0.0462 - val_accuracy: 0.9850\n",
      "Epoch 125/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0529 - accuracy: 0.9888 - val_loss: 0.0310 - val_accuracy: 0.9896\n",
      "Epoch 126/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0523 - accuracy: 0.9889 - val_loss: 0.0277 - val_accuracy: 0.9905\n",
      "Epoch 127/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0520 - accuracy: 0.9891 - val_loss: 0.0322 - val_accuracy: 0.9891\n",
      "Epoch 128/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0541 - accuracy: 0.9887 - val_loss: 0.0266 - val_accuracy: 0.9908\n",
      "Epoch 129/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0527 - accuracy: 0.9887 - val_loss: 0.0257 - val_accuracy: 0.9911\n",
      "Epoch 130/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0525 - accuracy: 0.9890 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
      "Epoch 131/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0519 - accuracy: 0.9890 - val_loss: 0.0264 - val_accuracy: 0.9908\n",
      "Epoch 132/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0527 - accuracy: 0.9888 - val_loss: 0.0353 - val_accuracy: 0.9880\n",
      "Epoch 133/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0523 - accuracy: 0.9890 - val_loss: 0.0394 - val_accuracy: 0.9865\n",
      "Epoch 134/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0513 - accuracy: 0.9892 - val_loss: 0.0390 - val_accuracy: 0.9872\n",
      "Epoch 135/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0521 - accuracy: 0.9890 - val_loss: 0.0243 - val_accuracy: 0.9915\n",
      "Epoch 136/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0516 - accuracy: 0.9890 - val_loss: 0.0239 - val_accuracy: 0.9923\n",
      "Epoch 137/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0511 - accuracy: 0.9892 - val_loss: 0.0331 - val_accuracy: 0.9886\n",
      "Epoch 138/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0519 - accuracy: 0.9891 - val_loss: 0.0265 - val_accuracy: 0.9909\n",
      "Epoch 139/200\n",
      "734/734 [==============================] - 18s 25ms/step - loss: 0.0508 - accuracy: 0.9891 - val_loss: 0.0237 - val_accuracy: 0.9918\n",
      "Epoch 140/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0511 - accuracy: 0.9891 - val_loss: 0.0241 - val_accuracy: 0.9918\n",
      "Epoch 141/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0509 - accuracy: 0.9892 - val_loss: 0.0217 - val_accuracy: 0.9926\n",
      "Epoch 142/200\n",
      "734/734 [==============================] - 19s 26ms/step - loss: 0.0527 - accuracy: 0.9889 - val_loss: 0.0336 - val_accuracy: 0.9883\n",
      "Epoch 143/200\n",
      "734/734 [==============================] - 20s 27ms/step - loss: 0.0511 - accuracy: 0.9892 - val_loss: 0.0442 - val_accuracy: 0.9854\n",
      "Epoch 144/200\n",
      "734/734 [==============================] - 21s 29ms/step - loss: 0.0518 - accuracy: 0.9890 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
      "Epoch 145/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0507 - accuracy: 0.9893 - val_loss: 0.0284 - val_accuracy: 0.9904\n",
      "Epoch 146/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0490 - accuracy: 0.9896 - val_loss: 0.0316 - val_accuracy: 0.9898\n",
      "Epoch 147/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0512 - accuracy: 0.9891 - val_loss: 0.0237 - val_accuracy: 0.9920\n",
      "Epoch 148/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0505 - accuracy: 0.9891 - val_loss: 0.0382 - val_accuracy: 0.9873\n",
      "Epoch 149/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0506 - accuracy: 0.9893 - val_loss: 0.0245 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0500 - accuracy: 0.9893 - val_loss: 0.0461 - val_accuracy: 0.9845\n",
      "Epoch 151/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0505 - accuracy: 0.9892 - val_loss: 0.0471 - val_accuracy: 0.9848\n",
      "Epoch 152/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0513 - accuracy: 0.9891 - val_loss: 0.0266 - val_accuracy: 0.9909\n",
      "Epoch 153/200\n",
      "734/734 [==============================] - 25s 34ms/step - loss: 0.0505 - accuracy: 0.9891 - val_loss: 0.0295 - val_accuracy: 0.9898\n",
      "Epoch 154/200\n",
      "734/734 [==============================] - 27s 37ms/step - loss: 0.0501 - accuracy: 0.9892 - val_loss: 0.0238 - val_accuracy: 0.9921\n",
      "Epoch 155/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0506 - accuracy: 0.9891 - val_loss: 0.0236 - val_accuracy: 0.9921\n",
      "Epoch 156/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0499 - accuracy: 0.9894 - val_loss: 0.0287 - val_accuracy: 0.9906\n",
      "Epoch 157/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0503 - accuracy: 0.9895 - val_loss: 0.0427 - val_accuracy: 0.9860\n",
      "Epoch 158/200\n",
      "734/734 [==============================] - 26s 35ms/step - loss: 0.0505 - accuracy: 0.9892 - val_loss: 0.0267 - val_accuracy: 0.9908\n",
      "Epoch 159/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0489 - accuracy: 0.9896 - val_loss: 0.0387 - val_accuracy: 0.9870\n",
      "Epoch 160/200\n",
      "734/734 [==============================] - 27s 37ms/step - loss: 0.0495 - accuracy: 0.9894 - val_loss: 0.0379 - val_accuracy: 0.9873\n",
      "Epoch 161/200\n",
      "734/734 [==============================] - 25s 33ms/step - loss: 0.0501 - accuracy: 0.9893 - val_loss: 0.0313 - val_accuracy: 0.9894\n",
      "Epoch 162/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.0275 - val_accuracy: 0.9904\n",
      "Epoch 163/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0505 - accuracy: 0.9891 - val_loss: 0.0292 - val_accuracy: 0.9900\n",
      "Epoch 164/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0489 - accuracy: 0.9894 - val_loss: 0.0321 - val_accuracy: 0.9890\n",
      "Epoch 165/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0489 - accuracy: 0.9895 - val_loss: 0.0436 - val_accuracy: 0.9860\n",
      "Epoch 166/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0496 - accuracy: 0.9895 - val_loss: 0.0254 - val_accuracy: 0.9912\n",
      "Epoch 167/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.0261 - val_accuracy: 0.9913\n",
      "Epoch 168/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0502 - accuracy: 0.9895 - val_loss: 0.0306 - val_accuracy: 0.9895\n",
      "Epoch 169/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0490 - accuracy: 0.9894 - val_loss: 0.0238 - val_accuracy: 0.9920\n",
      "Epoch 170/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0484 - accuracy: 0.9898 - val_loss: 0.0280 - val_accuracy: 0.9904\n",
      "Epoch 171/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0491 - accuracy: 0.9896 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
      "Epoch 172/200\n",
      "734/734 [==============================] - 24s 33ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 0.0224 - val_accuracy: 0.9926\n",
      "Epoch 173/200\n",
      "734/734 [==============================] - 24s 32ms/step - loss: 0.0489 - accuracy: 0.9895 - val_loss: 0.0219 - val_accuracy: 0.9925\n",
      "Epoch 174/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0490 - accuracy: 0.9896 - val_loss: 0.0235 - val_accuracy: 0.9922\n",
      "Epoch 175/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0491 - accuracy: 0.9895 - val_loss: 0.0245 - val_accuracy: 0.9916\n",
      "Epoch 176/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0487 - accuracy: 0.9896 - val_loss: 0.0311 - val_accuracy: 0.9894\n",
      "Epoch 177/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0494 - accuracy: 0.9895 - val_loss: 0.0231 - val_accuracy: 0.9921\n",
      "Epoch 178/200\n",
      "734/734 [==============================] - 26s 36ms/step - loss: 0.0488 - accuracy: 0.9895 - val_loss: 0.0301 - val_accuracy: 0.9897\n",
      "Epoch 179/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0484 - accuracy: 0.9897 - val_loss: 0.0254 - val_accuracy: 0.9913\n",
      "Epoch 180/200\n",
      "734/734 [==============================] - 25s 34ms/step - loss: 0.0491 - accuracy: 0.9896 - val_loss: 0.0343 - val_accuracy: 0.9885\n",
      "Epoch 181/200\n",
      "734/734 [==============================] - 27s 36ms/step - loss: 0.0478 - accuracy: 0.9898 - val_loss: 0.0514 - val_accuracy: 0.9840\n",
      "Epoch 182/200\n",
      "734/734 [==============================] - 24s 33ms/step - loss: 0.0481 - accuracy: 0.9897 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 183/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0487 - accuracy: 0.9897 - val_loss: 0.0272 - val_accuracy: 0.9907\n",
      "Epoch 184/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0482 - accuracy: 0.9897 - val_loss: 0.0240 - val_accuracy: 0.9917\n",
      "Epoch 185/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0480 - accuracy: 0.9897 - val_loss: 0.0198 - val_accuracy: 0.9932\n",
      "Epoch 186/200\n",
      "734/734 [==============================] - 22s 29ms/step - loss: 0.0486 - accuracy: 0.9897 - val_loss: 0.0255 - val_accuracy: 0.9913\n",
      "Epoch 187/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0479 - accuracy: 0.9897 - val_loss: 0.0485 - val_accuracy: 0.9845\n",
      "Epoch 188/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0480 - accuracy: 0.9898 - val_loss: 0.0220 - val_accuracy: 0.9926\n",
      "Epoch 189/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0486 - accuracy: 0.9898 - val_loss: 0.0316 - val_accuracy: 0.9892\n",
      "Epoch 190/200\n",
      "734/734 [==============================] - 23s 31ms/step - loss: 0.0474 - accuracy: 0.9898 - val_loss: 0.0277 - val_accuracy: 0.9909\n",
      "Epoch 191/200\n",
      "734/734 [==============================] - 22s 29ms/step - loss: 0.0475 - accuracy: 0.9899 - val_loss: 0.0388 - val_accuracy: 0.9868\n",
      "Epoch 192/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0477 - accuracy: 0.9898 - val_loss: 0.0229 - val_accuracy: 0.9923\n",
      "Epoch 193/200\n",
      "734/734 [==============================] - 23s 31ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.0213 - val_accuracy: 0.9928\n",
      "Epoch 194/200\n",
      "734/734 [==============================] - 22s 31ms/step - loss: 0.0464 - accuracy: 0.9900 - val_loss: 0.0442 - val_accuracy: 0.9856\n",
      "Epoch 195/200\n",
      "734/734 [==============================] - 22s 31ms/step - loss: 0.0463 - accuracy: 0.9901 - val_loss: 0.0237 - val_accuracy: 0.9919\n",
      "Epoch 196/200\n",
      "734/734 [==============================] - 23s 31ms/step - loss: 0.0484 - accuracy: 0.9897 - val_loss: 0.0246 - val_accuracy: 0.9917\n",
      "Epoch 197/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.0364 - val_accuracy: 0.9880\n",
      "Epoch 198/200\n",
      "734/734 [==============================] - 22s 30ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 0.0296 - val_accuracy: 0.9903\n",
      "Epoch 199/200\n",
      "734/734 [==============================] - 22s 31ms/step - loss: 0.0480 - accuracy: 0.9897 - val_loss: 0.0278 - val_accuracy: 0.9903\n",
      "Epoch 200/200\n",
      "734/734 [==============================] - 19s 25ms/step - loss: 0.0471 - accuracy: 0.9898 - val_loss: 0.0377 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "#обучение 7 разных моделей с кратно увеличивающимся количеством конволюционных слоев\n",
    "dim=16\n",
    "modelhs=[]\n",
    "ps=32\n",
    "for i in range(1): #7\n",
    "    model = load_model('model14ll16.h5')\n",
    "    '''\n",
    "    print(dim)\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(dim, kernel_size=(3,3), padding='same', input_shape=(ps, ps, 1), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(dim, (3,3), padding='same', activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(dim*2, (3,3), padding='same', activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(dim*2, (3,3), padding='same', activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    \n",
    "    \n",
    "    model.add(Flatten(input_shape=(32, 32, 1)))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(BatchNormalization())  \n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.01, decay=0.025 / 200, momentum=0.9, nesterov=False)\n",
    "    model.compile(optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    '''\n",
    "    class_weights = {0: 1.,\n",
    "                    1: weight}\n",
    "\n",
    "    K.set_value(model.optimizer.learning_rate, 0.005)\n",
    "    model.summary()\n",
    "    # train the network\n",
    "    H=model.fit(Xtrain, ytrain, epochs=200, validation_data=(Xtest, ytest),class_weight =class_weights, verbose=1,shuffle = True, batch_size=1000)\n",
    "    model.save('model14x'+str(16)+'n.h5', overwrite=True)\n",
    "    #формирование массива с историей обучения моделей\n",
    "    modelhs.append(dim)\n",
    "    modelhs.append(H.history['loss'])\n",
    "    modelhs.append(H.history[\"val_loss\"])\n",
    "    modelhs.append(H.history[\"accuracy\"])\n",
    "    modelhs.append(H.history[\"val_accuracy\"])\n",
    "    dim=dim*2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение результатов обучения\n",
    "filename='modellearn_data'\n",
    "pickle.dump(modelhs, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
